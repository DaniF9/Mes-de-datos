{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploración de datos con Python\n",
    "Una parte importante del papel de un científico de datos es explorar, analizar y visualizar datos. Hay muchas herramientas y lenguajes de programación que pueden utilizar para ello. Uno de los enfoques más populares es utilizar cuadernos Jupyter (como éste) y Python.\n",
    "\n",
    "Python es un lenguaje de programación flexible que se utiliza en una amplia gama de escenarios, desde aplicaciones web hasta programación de dispositivos. Es muy popular en la ciencia de datos y la comunidad de aprendizaje automático debido a los muchos paquetes que soporta para el análisis de datos y visualización.\n",
    "\n",
    "En este cuaderno, exploraremos algunos de estos paquetes y aplicaremos técnicas básicas para analizar datos. No pretende ser un ejercicio exhaustivo de programación en Python, ni siquiera una inmersión profunda en el análisis de datos. Más bien, pretende ser un curso intensivo de algunas de las formas más comunes en que los científicos de datos pueden utilizar Python para trabajar con datos.\n",
    "\n",
    "Nota: Si nunca has utilizado el entorno de Jupyter Notebooks, hay algunas cosas que debes tener en cuenta:\n",
    "Los cuadernos se componen de celdas. Algunas celdas (como ésta) contienen texto markdown, mientras que otras (como la que está debajo de ésta) contienen código.\n",
    "Puedes ejecutar cada celda de código utilizando el botón ► Ejecutar. El botón ► Ejecutar aparecerá cuando pase el ratón por encima de la celda.\n",
    "La salida de cada celda de código se mostrará inmediatamente debajo de la celda.\n",
    "Aunque las celdas de código pueden ejecutarse individualmente, algunas variables utilizadas en el código son globales para el cuaderno. Esto significa que debe ejecutar todas las celdas de código en orden. Puede haber dependencias entre las celdas de código, por lo que si te saltas una celda, las siguientes podrían no ejecutarse correctamente.\n",
    "Explorando matrices de datos con NumPy\n",
    "Empecemos por ver algunos datos sencillos.\n",
    "\n",
    "Supongamos que un profesor universitario toma una muestra de las notas de los estudiantes de una clase para analizarlas.\n",
    "\n",
    "Ejecuta el código de la celda de abajo pulsando el botón ► Ejecutar para ver los datos.\n",
    "\n",
    "Traducción realizada con la versión gratuita del traductor www.DeepL.com/Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 50, 47, 97, 49, 3, 53, 42, 26, 74, 82, 62, 37, 15, 70, 27, 36, 35, 48, 52, 63, 64]\n"
     ]
    }
   ],
   "source": [
    "data = [50,50,47,97,49,3,53,42,26,74,82,62,37,15,70,27,36,35,48,52,63,64]\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos se han cargado en una estructura de lista de Python, que es un buen tipo de datos para la manipulación general de datos, pero no está optimizado para el análisis numérico. Para ello, vamos a utilizar el paquete NumPy, que incluye tipos de datos y funciones específicas para trabajar con números en Python.\n",
    "\n",
    "Ejecuta la celda de abajo para cargar los datos en un array NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50 50 47 97 49  3 53 42 26 74 82 62 37 15 70 27 36 35 48 52 63 64]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "grades = np.array(data)\n",
    "print(grades)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por si te estás preguntando cuáles son las diferencias entre una lista y un array NumPy, vamos a comparar cómo se comportan estos tipos de datos cuando los utilizamos en una expresión que los multiplica por 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> x 2: [50, 50, 47, 97, 49, 3, 53, 42, 26, 74, 82, 62, 37, 15, 70, 27, 36, 35, 48, 52, 63, 64, 50, 50, 47, 97, 49, 3, 53, 42, 26, 74, 82, 62, 37, 15, 70, 27, 36, 35, 48, 52, 63, 64]\n",
      "---\n",
      "<class 'numpy.ndarray'> x 2: [100 100  94 194  98   6 106  84  52 148 164 124  74  30 140  54  72  70\n",
      "  96 104 126 128]\n"
     ]
    }
   ],
   "source": [
    "print (type(data),'x 2:', data * 2)\n",
    "print('---')\n",
    "print (type(grades),'x 2:', grades * 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que multiplicar una lista por 2 crea una nueva lista del doble de longitud con la secuencia original de elementos de la lista repetida. La multiplicación de una matriz NumPy por otro lado realiza un cálculo elemento a elemento en el que la matriz se comporta como un vector, por lo que terminamos con una matriz del mismo tamaño en el que cada elemento se ha multiplicado por 2.\n",
    "\n",
    "La clave es que las matrices de NumPy están diseñadas específicamente para soportar operaciones matemáticas sobre datos numéricos, lo que las hace más útiles para el análisis de datos que una lista genérica.\n",
    "\n",
    "Es posible que hayas notado que el tipo de clase para el arreglo NumPy anterior es numpy.ndarray. La nd indica que se trata de una estructura que puede constar de múltiples dimensiones. (Puede tener n dimensiones.) Nuestra instancia específica tiene una sola dimensión de calificaciones de estudiantes.\n",
    "\n",
    "Ejecuta la celda de abajo para ver la forma del array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma confirma que esta matriz sólo tiene una dimensión, que contiene 22 elementos. (Hay 22 grados en la lista original.) Puedes acceder a los elementos individuales de la matriz por su posición ordinal basada en cero. Obtengamos el primer elemento (el que está en la posición 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya sabes cómo funciona una matriz NumPy, es hora de realizar algún análisis de los datos de las calificaciones.\n",
    "\n",
    "Puedes aplicar agregaciones a través de los elementos del array, así que vamos a encontrar la nota media simple (en otras palabras, el valor medio de la nota)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto, la nota media se sitúa en torno a 50, más o menos en el centro del intervalo posible de 0 a 100.\n",
    "\n",
    "Añadamos una segunda serie de datos de los mismos estudiantes. Esta vez, registraremos el número típico de horas semanales que dedican al estudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an array of study hours\n",
    "study_hours = [10.0,11.5,9.0,16.0,9.25,1.0,11.5,9.0,8.5,14.5,15.5,\n",
    "               13.75,9.0,8.0,15.5,8.0,9.0,6.0,10.0,12.0,12.5,12.0]\n",
    "\n",
    "# Create a 2D array (an array of arrays)\n",
    "student_data = np.array([study_hours, grades])\n",
    "\n",
    "# display the array\n",
    "student_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora los datos consisten en una matriz bidimensional, una matriz de matrices. Veamos su forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show shape of 2D array\n",
    "student_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz student_data contiene dos elementos, cada uno de los cuales es una matriz que contiene 22 elementos.\n",
    "\n",
    "Para navegar por esta estructura, es necesario especificar la posición de cada elemento en la jerarquía. Así, para encontrar el primer valor de la primera matriz (que contiene los datos de horas de estudio), puede utilizar el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first element of the first element\n",
    "student_data[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tiene una matriz multidimensional que contiene tanto el tiempo de estudio del estudiante como la información de la calificación, que puede utilizar para comparar el tiempo de estudio con la calificación de un estudiante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean value of each sub-array\n",
    "avg_study = student_data[0].mean()\n",
    "avg_grade = student_data[1].mean()\n",
    "\n",
    "print('Average study hours: {:.2f}\\nAverage grade: {:.2f}'.format(avg_study, avg_grade))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorando datos tabulares con Pandas\n",
    "NumPy proporciona muchas de las funcionalidades y herramientas que necesitas para trabajar con números, como arrays de valores numéricos. Sin embargo, cuando empiezas a tratar con tablas bidimensionales de datos, el paquete Pandas ofrece una estructura más cómoda para trabajar: el DataFrame.\n",
    "\n",
    "Ejecute la siguiente celda para importar la librería Pandas y crear un DataFrame con tres columnas. La primera columna es una lista de nombres de estudiantes, y la segunda y tercera columnas son las matrices NumPy que contienen los datos de tiempo de estudio y calificación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_students = pd.DataFrame({'Name': ['Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic', 'Jimmie', \n",
    "                                     'Rhonda', 'Giovanni', 'Francesca', 'Rajab', 'Naiyana', 'Kian', 'Jenny',\n",
    "                                     'Jakeem','Helena','Ismat','Anila','Skye','Daniel','Aisha'],\n",
    "                            'StudyHours':student_data[0],\n",
    "                            'Grade':student_data[1]})\n",
    "\n",
    "df_students "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que, además de las columnas especificadas, el DataFrame incluye un índice para identificar de forma exclusiva cada fila. Podríamos haber especificado el índice explícitamente y haber asignado cualquier tipo de valor apropiado (por ejemplo, una dirección de correo electrónico). Sin embargo, como no hemos especificado un índice, se ha creado uno con un valor entero único para cada fila.\n",
    "\n",
    "Buscar y filtrar datos en un DataFrame\n",
    "Puede utilizar el método loc del DataFrame para recuperar datos para un valor de índice específico, de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data for index value 5\n",
    "df_students.loc[5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puedes obtener los datos en un rango de valores de índice, de esta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rows with index values from 0 to 5\n",
    "df_students.loc[0:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de poder utilizar el método loc para encontrar filas basándose en el índice, puede utilizar el método iloc para encontrar filas basándose en su posición ordinal en el DataFrame (independientemente del índice):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data in the first five rows\n",
    "df_students.iloc[0:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa detenidamente los resultados de iloc[0:5] y compáralos con los de loc[0:5] que obtuviste anteriormente. ¿Puede detectar la diferencia?\n",
    "\n",
    "El método loc devolvía las filas con etiqueta de índice en la lista de valores de 0 a 5, que incluye 0, 1, 2, 3, 4 y 5 (seis filas). Sin embargo, el método iloc devuelve las filas en las posiciones incluidas en el rango de 0 a 5. Dado que los rangos de enteros no incluyen el valor del límite superior, esto incluye las posiciones 0, 1, 2, 3 y 4 (cinco filas).\n",
    "\n",
    "iloc identifica valores de datos en un DataFrame por posición, que se extiende más allá de las filas a las columnas. Así, por ejemplo, puede utilizarlo para encontrar los valores de las columnas en las posiciones 1 y 2 de la fila 0, de esta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students.iloc[0,[1,2]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvamos al método loc y veamos cómo funciona con columnas. Recuerde que loc se utiliza para localizar elementos de datos basados en valores de índice en lugar de posiciones. En ausencia de una columna índice explícita, las filas de nuestro DataFrame se indexan como valores enteros, pero las columnas se identifican por su nombre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students.loc[0,'Grade']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He aquí otro truco útil. Puede utilizar el método loc para encontrar filas indexadas basándose en una expresión de filtrado que haga referencia a columnas con nombre que no sean el índice, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students.loc[df_students['Name']=='Aisha']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En realidad, no es necesario utilizar explícitamente el método loc para hacer esto. Puede simplemente aplicar una expresión de filtrado DataFrame, como esta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students[df_students['Name']=='Aisha']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y por si fuera poco, puedes conseguir los mismos resultados utilizando el método de consulta del DataFrame, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students.query('Name==\"Aisha\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tres ejemplos anteriores subrayan una verdad confusa sobre el trabajo con Pandas. A menudo, hay múltiples formas de conseguir los mismos resultados. Otro ejemplo de esto es la forma de referirse al nombre de columna de un DataFrame. Puede especificar el nombre de la columna como un valor de índice con nombre (como en los ejemplos df_students['Nombre'] que hemos visto hasta ahora), o puede utilizar la columna como una propiedad del DataFrame, como en este caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students[df_students.Name == 'Aisha']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar un DataFrame desde un fichero\n",
    "Hemos construido el DataFrame a partir de algunas matrices existentes. Sin embargo, en muchos escenarios del mundo real, los datos se cargan desde fuentes como archivos. Sustituyamos el DataFrame de las notas de los alumnos por el contenido de un fichero de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/grades.csv\n",
    "df_students = pd.read_csv('grades.csv',delimiter=',',header='infer')\n",
    "df_students.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método read_csv de DataFrame se utiliza para cargar datos de archivos de texto. Como puede ver en el código de ejemplo, puede especificar opciones como el delimitador de columna y qué fila (si la hay) contiene cabeceras de columna. (En este caso, el delimitador es una coma y la primera fila contiene los nombres de las columnas. Estos son los ajustes por defecto, por lo que los parámetros podrían haberse omitido).\n",
    "\n",
    "Tratamiento de los valores omitidos\n",
    "Uno de los problemas más comunes a los que se enfrentan los científicos de datos son los datos incompletos o ausentes. ¿Cómo podemos saber que el DataFrame contiene valores perdidos? Puede utilizar el método isnull para identificar qué valores individuales son nulos, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students.isnull()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por supuesto, con un DataFrame más grande, sería ineficiente revisar todas las filas y columnas individualmente, por lo que podemos obtener la suma de valores perdidos para cada columna de esta manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sabemos que falta un valor de Horas de estudio y dos valores de Notas.\n",
    "\n",
    "Para verlos en contexto, podemos filtrar el DataFrame para incluir sólo las filas en las que alguna de las columnas (eje 1 del DataFrame) sea nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students[df_students.isnull().any(axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se recupera el DataFrame, los valores numéricos que faltan aparecen como NaN (no es un número).\n",
    "\n",
    "Ahora que hemos encontrado los valores nulos, ¿qué podemos hacer con ellos?\n",
    "\n",
    "Un método habitual es imputar valores de sustitución. Por ejemplo, si falta el número de horas de estudio, podemos suponer que el alumno estudió una media de tiempo y sustituir el valor que falta por la media de horas de estudio. Para ello, podemos utilizar el método fillna de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students.StudyHours = df_students.StudyHours.fillna(df_students.StudyHours.mean())\n",
    "df_students"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, puede ser importante asegurarse de que sólo utiliza datos que sabe que son absolutamente correctos. En este caso, puede eliminar filas o columnas que contengan valores nulos utilizando el método dropna. Por ejemplo, eliminaremos las filas (eje 0 del DataFrame) en las que alguna de las columnas contenga valores nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students = df_students.dropna(axis=0, how='any')\n",
    "df_students"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorar los datos en el DataFrame\n",
    "Ahora que hemos limpiado los valores que faltaban, estamos listos para explorar los datos en el DataFrame. Empecemos comparando la media de horas de estudio y las calificaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean study hours using to column name as an index\n",
    "mean_study = df_students['StudyHours'].mean()\n",
    "\n",
    "# Get the mean grade using the column name as a property (just to make the point!)\n",
    "mean_grade = df_students.Grade.mean()\n",
    "\n",
    "# Print the mean study hours and mean grade\n",
    "print('Average weekly study hours: {:.2f}\\nAverage grade: {:.2f}'.format(mean_study, mean_grade))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Bien, vamos a filtrar el DataFrame para encontrar sólo los estudiantes que estudiaron durante más tiempo que la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get students who studied for the mean or more hours\n",
    "df_students[df_students.StudyHours > mean_study]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que el resultado filtrado es en sí mismo un DataFrame, por lo que puede trabajar con sus columnas como con cualquier otro DataFrame.\n",
    "\n",
    "Por ejemplo, busquemos la nota media de los estudiantes que dedicaron más tiempo al estudio que la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was their mean grade?\n",
    "df_students[df_students.StudyHours > mean_study].Grade.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que la nota de aprobado del curso es 60.\n",
    "\n",
    "Podemos utilizar esa información para añadir una nueva columna al DataFrame que indique si cada alumno ha aprobado o no.\n",
    "\n",
    "Primero, crearemos una Serie Pandas que contenga el indicador de aprobado/no aprobado (Verdadero o Falso), y luego concatenaremos esa serie como una nueva columna (eje 1) en el DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passes  = pd.Series(df_students['Grade'] >= 60)\n",
    "df_students = pd.concat([df_students, passes.rename(\"Pass\")], axis=1)\n",
    "\n",
    "df_students"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los DataFrames están diseñados para datos tabulares, y puede utilizarlos para realizar muchos de los mismos tipos de operaciones de análisis de datos que puede hacer en una base de datos relacional, como agrupar y agregar tablas de datos.\n",
    "\n",
    "Por ejemplo, puede utilizar el método groupby para agrupar los datos de los alumnos en grupos basados en la columna Pass que añadió anteriormente y contar el número de nombres de cada grupo. En otras palabras, puede determinar cuántos alumnos aprobaron y cuántos suspendieron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_students.groupby(df_students.Pass).Name.count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede agregar múltiples campos en un grupo utilizando cualquier función de agregación disponible. Por ejemplo, puede encontrar el tiempo medio de estudio y la calificación de los grupos de alumnos que aprobaron y suspendieron el curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_students.groupby(df_students.Pass)['StudyHours', 'Grade'].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los DataFrames son increíblemente versátiles y facilitan la manipulación de datos. Muchas operaciones con DataFrame devuelven una nueva copia del DataFrame. Así que si quieres modificar un DataFrame pero mantener la variable existente, necesitas asignar el resultado de la operación a la variable existente. Por ejemplo, el siguiente código ordena los datos de los estudiantes en orden descendente por Grado y asigna el DataFrame ordenado resultante a la variable original df_students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the data sorted by Grade (descending)\n",
    "df_students = df_students.sort_values('Grade', ascending=False)\n",
    "\n",
    "# Show the DataFrame\n",
    "df_students"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumen\n",
    "NumPy y DataFrames son los caballos de batalla de la ciencia de datos en Python. Nos proporcionan formas de cargar, explorar y analizar datos tabulares. Como veremos en módulos posteriores, incluso los métodos de análisis avanzados suelen depender de NumPy y Pandas para estas importantes funciones.\n",
    "\n",
    "En nuestro próximo libro de trabajo, echaremos un vistazo a cómo crear gráficos y explorar tus datos de formas más interesantes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
